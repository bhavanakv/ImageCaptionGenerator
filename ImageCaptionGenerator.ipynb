{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecea81f8",
   "metadata": {},
   "source": [
    "# Image Caption Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffb55b",
   "metadata": {},
   "source": [
    "This project is an analysis of some images where the deep learning models recognize the context of the images and describe them in natural language - English here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fcb5c",
   "metadata": {},
   "source": [
    "All the libraries needed are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc30ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # handling the files\n",
    "import pickle # storing numpy features\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f5de33",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2f285",
   "metadata": {},
   "source": [
    "The data used in this analysis consists of two datasets -\n",
    "1. Flickr8k dataset \n",
    "2. IAPRTC12 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128dca9",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d367f7b5",
   "metadata": {},
   "source": [
    "The captions of these two datasets are stored in two separate files. The captions are loaded and these are stored in a dictionary with image name as key and captions as value in the form of any array. These are later cleaned to remove noise in the captions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9120a173",
   "metadata": {},
   "source": [
    "### Load captions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ab89673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the captions file\n",
    "with open('Data/captions_dataset1.txt', 'r') as file:\n",
    "    captions_dataset1 = file.readlines()\n",
    "    \n",
    "with open('Data/captions_dataset2.txt', 'r') as file:\n",
    "    captions_dataset2 = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "695a0a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 12800\n"
     ]
    }
   ],
   "source": [
    "# Mapping the image and captions into a dictionary\n",
    "mapping = {}\n",
    "\n",
    "# Dataset1\n",
    "for line in captions_dataset1[1:]:\n",
    "    tokens = line.split(',')\n",
    "    key = tokens[0]\n",
    "    caption = tokens[1]\n",
    "    if key not in mapping:\n",
    "        mapping[key] = []\n",
    "    mapping[key].append(caption)\n",
    "\n",
    "# Dataset2\n",
    "for line in captions_dataset2[1:]:\n",
    "    tokens = line.split(';')\n",
    "    key = tokens[0]\n",
    "    caption = tokens[1]\n",
    "    if key not in mapping:\n",
    "        mapping[key] = []\n",
    "    mapping[key].append(caption)\n",
    "\n",
    "print(\"Total number of images: \" + str(len(mapping)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37e1ee",
   "metadata": {},
   "source": [
    "### Cleaning the captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd59af",
   "metadata": {},
   "source": [
    "The captions are cleaned such that irrelevant characters such as digits, special characters are removed. Also, extra spaces are trimmed. The case of all captions are made lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f4967ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the case and replacing irrelevant characters \n",
    "for image, captions in mapping.items():\n",
    "    for i in range(len(captions)):\n",
    "        cleaned_caption = captions[i].lower().replace('[^A-Za-z]', '').replace('\\s+', ' ')\n",
    "        processed_caption = 'startseq ' + \" \".join([word for word in cleaned_caption.split() if len(word)>1]) + ' endseq'\n",
    "        captions[i] = processed_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8df65f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of possible captions: 48899\n"
     ]
    }
   ],
   "source": [
    "# Storing all the possible captions into a list for tokenization\n",
    "all_captions = []\n",
    "for key in mapping:\n",
    "    for caption in mapping[key]:\n",
    "        all_captions.append(caption)\n",
    "        \n",
    "print(\"Total number of possible captions: \" + str(len(all_captions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9fa0d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq child in pink dress is climbing up set of stairs in an entry way endseq',\n",
       " 'startseq girl going into wooden building endseq',\n",
       " 'startseq little girl climbing into wooden playhouse endseq',\n",
       " 'startseq little girl climbing the stairs to her playhouse endseq',\n",
       " 'startseq little girl in pink dress going into wooden cabin endseq']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processed captions after cleaning\n",
    "all_captions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befacad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
